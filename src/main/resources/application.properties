#============== kafka ===================
# 指定kafka 代理地址，可以多个
spring.kafka.bootstrap-servers=192.168.1.10:9092

#logging.level.root=debug

#=============== provider  =======================
# 消息发送错误的时候， 重试的次数
spring.kafka.producer.retries=0
# 每次批量发送消息的数量
spring.kafka.producer.batch-size=4096
spring.kafka.producer.buffer-memory=3355443
# 消息填充满批次的等待时长， 没有填满的时候超时会发送数据
spring.kafka.producer.linger=1
# 指定消息key和消息体的编解码方式
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
# 如果是集群， 则复制到所有的节点
# 1 只要集群的首领节点收到就可以了
# 0 生产者发送消息后就不管了
spring.kafka.producer.acks=all
# 消息的压缩方式
# snappy 占用CPU小
# gzip 压缩比高， CPU使用率相对较高
# lz4
spring.kafka.producer.compression-type=snappy




#=============== consumer  =======================
# 指定默认消费者group id
spring.kafka.consumer.group-id=ID-KAFKA
spring.kafka.consumer.auto-offset-reset=latest
spring.kafka.consumer.enable-auto-commit=true
spring.kafka.consumer.auto-commit-interval=100
spring.kafka.listener.poll-timeout=6000
spring.kafka.listener.concurrency=10
# 指定消息key和消息体的编解码方式
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer